{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses a **Long Short Term Memory (LSTM) Neural Network** to predict if the price is going up or down. This example was build for the **Q18 NASDAQ-100 Stock Long-Short contest**.\n",
    "\n",
    "**Important!** *When developing further you need to run the ./init.py file once in order to install the pytorch dependency.*\n",
    " \n",
    "**Strategy idea:** We will go long on cryptocurrencies depending on predictions of **LSTM NN** regarding of how sure the NN is the that the price is moving up.\n",
    "\n",
    "**Feature for learning** -  logarithm of closing price\n",
    "\n",
    "To have a look at all the technical indicators we offer, go to [**Technical Indicators**](https://quantiacs.com/documentation/en/user_guide/technical_indicators.html)\n",
    "\n",
    "---\n",
    "\n",
    "We will use a **specialized** version of the Quantiacs backtester for this purpose, which dramatically speeds up the backtesting process when the models should be retrained on a regular basis.\n",
    "\n",
    "**Need help?** Check the [**Documentation**](https://quantiacs.com/documentation/en/) and find solutions/report problems in the [**Forum**](https://quantiacs.com/community/categories) section.\n",
    "\n",
    "**More help with Jupyter?** Check the official [**Jupyter**](https://jupyter.org/) page.\n",
    "\n",
    "Once you are done, click on **Submit to the contest** and take part to our competitions.\n",
    "\n",
    "Learn more about **LSTM**: [**PyTorch**](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "\n",
    "API reference:\n",
    "\n",
    "* **data**: check how to work with [data](https://quantiacs.com/documentation/en/reference/data_load_functions.html);\n",
    "\n",
    "* **backtesting**: read how to run the [simulation](https://quantiacs.com/documentation/en/reference/evaluation.html) and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.IPython && (IPython.OutputArea.prototype._should_scroll = function(lines) { return false; })\n",
       "// disable widget scrolling\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "window.IPython && (IPython.OutputArea.prototype._should_scroll = function(lines) { return false; })\n",
    "// disable widget scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multi-Pass implementation of a trivial crossover system using the Quantiacs built-in backtester.\n",
    "import xarray as xr           # xarray for data manipulation\n",
    "import qnt.data as qndata     # functions for loading data\n",
    "import qnt.backtester as qnbt # built-in backtester\n",
    "import qnt.ta as qnta         # technical analysis library\n",
    "import numpy as np\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data):\n",
    "    \"\"\"\n",
    "        get the features: for this example we only use the logarithm of the closing price\n",
    "    \n",
    "    \"\"\"\n",
    "    price= data.sel(field=\"close\").ffill('time').bfill('time').fillna(1)\n",
    "    price=np.log(price)\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_classes(data):\n",
    "    price_current = data.sel(field='close')\n",
    "    price_future = qnta.shift(price_current, -1)\n",
    "\n",
    "    class_positive = 1 #prices goes up\n",
    "    class_negative = 0 #price goes down\n",
    "\n",
    "    target_price_up = xr.where(price_future > price_current, class_positive, class_negative)\n",
    "\n",
    "    return target_price_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "        class to define our LSTM network\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_layers=64):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        # lstm1, lstm2, linear are all layers in the network\n",
    "        self.lstm1 = nn.LSTMCell(1, self.hidden_layers)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_layers, self.hidden_layers)\n",
    "        self.linear = nn.Linear(self.hidden_layers, 1)\n",
    "        \n",
    "    #define the foward function\n",
    "    def forward(self, y, future_preds=0):\n",
    "        outputs, n_samples = [], y.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        \n",
    "        for time_step in y.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(time_step, (h_t, c_t)) # initial hidden and cell states\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2)) # new hidden and cell states\n",
    "            output = self.linear(h_t2) # output from the last FC layer\n",
    "            outputs.append(output)\n",
    "            \n",
    "        for i in range(future_preds):\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        # transform list to tensor    \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = LSTM()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data):\n",
    "    \"\"\"\n",
    "        train the LSTM network\n",
    "    \"\"\"\n",
    "    \n",
    "    asset_name_all = ['NAS:AAPL', 'NAS:AMZN' , 'NAS:MSFT']\n",
    "\n",
    "    features_all = get_features(data)\n",
    "    target_all = get_target_classes(data)\n",
    "\n",
    "    models = dict()\n",
    "    \n",
    "    for asset_name in asset_name_all:\n",
    "        model = get_model()\n",
    "        \n",
    "        # drop missing values:\n",
    "        target_cur = target_all.sel(asset=asset_name).dropna('time', 'any')\n",
    "        features_cur = features_all.sel(asset=asset_name).dropna('time', 'any')\n",
    "\n",
    "        # align features and targets:\n",
    "        target_for_learn_df, feature_for_learn_df = xr.align(target_cur, features_cur, join='inner')\n",
    "        \n",
    "        criterion = nn.MSELoss() # define loss function\n",
    "\n",
    "        optimiser = optim.LBFGS(model.parameters(), lr=0.08) # we use an LBFGS solver as optimiser\n",
    "        epochs = 1 #how many epochs \n",
    "        for i in range(epochs):\n",
    "                def closure(): # reevaluates the model and returns the loss (forward pass)\n",
    "                    optimiser.zero_grad()\n",
    "\n",
    "                    #input tensor\n",
    "                    in_ = torch.zeros(1,len(feature_for_learn_df.values))\n",
    "                    in_[0,:]=torch.tensor(np.array(feature_for_learn_df.values))\n",
    "\n",
    "                    #output\n",
    "                    out = model(in_)\n",
    "\n",
    "                    #target tensor\n",
    "                    target = torch.zeros(1,len(target_for_learn_df.values))\n",
    "                    target[0,:]=torch.tensor(np.array(target_for_learn_df.values))\n",
    "\n",
    "                    #evaluate loss\n",
    "                    loss = criterion(out, target)\n",
    "                    loss.backward()\n",
    "\n",
    "                    return loss\n",
    "                optimiser.step(closure) #updates weights\n",
    "                \n",
    "        models[asset_name] = model\n",
    "            \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models,data):\n",
    "    \"\"\"\n",
    "        predict if price is going up or down and go long depending on it\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    asset_name_all = ['NAS:AAPL', 'NAS:AMZN' , 'NAS:MSFT']\n",
    "    weights = xr.zeros_like(data.sel(field='close'))\n",
    "    \n",
    "    for asset_name in asset_name_all:\n",
    "        features_all = get_features(data)\n",
    "        features_cur = features_all.sel(asset=asset_name).dropna('time','any')\n",
    "        if len(features_cur.time) < 1:\n",
    "            continue\n",
    "            \n",
    "        #input tensor\n",
    "        in_ = torch.zeros(1,len(features_cur.values))\n",
    "        in_[0,:]=torch.tensor(np.array(features_cur.values))\n",
    "        \n",
    "        #output\n",
    "        out = models[asset_name](in_)\n",
    "        \n",
    "        prediction = out.detach()[0]\n",
    "        \n",
    "        weights.loc[dict(asset=asset_name,time=features_cur.time.values)] = prediction\n",
    "                \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the last iteration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (18272 of 18272) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (7279936 of 7279936) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/1 1s\n",
      "Data loaded 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (373944 of 373944) |################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/1 1s\n",
      "Data loaded 1s\n",
      "Output cleaning...\n",
      "fix uniq\n",
      "ffill if the current price is None...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Normalization...\n",
      "Output cleaning is complete.\n",
      "Write output: /root/fractions.nc.gz\n",
      "State saved.\n",
      "---\n",
      "Run First Iteration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (13214 of 13214) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (5189572 of 5189572) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/1 1s\n",
      "Data loaded 1s\n",
      "---\n",
      "Run all iterations...\n",
      "Load data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (34173 of 34173) |##################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (14862360 of 14862360) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/7 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (14862360 of 14862360) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 2/7 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (14862332 of 14862332) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 3/7 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (14862252 of 14862252) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 4/7 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (14885324 of 14885324) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 5/7 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (15107472 of 15107472) |############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 6/7 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2247380 of 2247380) |##############| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 7/7 5s\n",
      "Data loaded 5s\n",
      "fetched chunk 1/5 0s\n",
      "fetched chunk 2/5 0s\n",
      "fetched chunk 3/5 0s\n",
      "fetched chunk 4/5 0s\n",
      "fetched chunk 5/5 0s\n",
      "Data loaded 0s\n",
      "Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (4227 of 4228) |################### | Elapsed Time: 0:35:58 ETA:   0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched chunk 1/5 0s\n",
      "fetched chunk 2/5 0s\n",
      "fetched chunk 3/5 0s\n",
      "fetched chunk 4/5 0s\n",
      "fetched chunk 5/5 0s\n",
      "Data loaded 0s\n",
      "Output cleaning...\n",
      "fix uniq\n",
      "ffill if the current price is None...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Normalization...\n",
      "Output cleaning is complete.\n",
      "Write output: /root/fractions.nc.gz\n",
      "State saved.\n",
      "---\n",
      "Analyze results...\n",
      "Check...\n",
      "Check liquidity...\n",
      "Ok.\n",
      "Check missed dates...\n",
      "Ok.\n",
      "Check the sharpe ratio...\n",
      "Period: 2006-01-01 - 2022-06-16\n",
      "Sharpe Ratio = 0.9254618305474261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR! The Sharpe Ratio is too low. 0.9254618305474261 < 1\n",
      "Improve the strategy and make sure that the in-sample Sharpe Ratio more than 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check correlation.\n",
      "\n",
      "Ok. This strategy does not correlate with other strategies.\n",
      "---\n",
      "Align...\n",
      "Calc global stats...\n",
      "---\n",
      "Calc stats per asset...\n",
      "Build plots...\n",
      "---\n",
      "Select the asset (or leave blank to display the overall stats):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a81acb7c0d4afa80afe6d38e797b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Combobox(value='', description='asset', options=('', 'NAS:AAL', 'NAS:AAPL', 'NAS:ABNB', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4228 of 4228) |####################| Elapsed Time: 0:36:42 Time:  0:36:42\n"
     ]
    }
   ],
   "source": [
    "weights = qnbt.backtest_ml(\n",
    "    train=train_model,\n",
    "    predict=predict,\n",
    "    train_period=3*365,   # the data length for training in calendar days\n",
    "    retrain_interval=365,  # how often we have to retrain models (calendar days)\n",
    "    retrain_interval_after_submit=1, # how often retrain models after submission during evaluation (calendar days)\n",
    "    predict_each_day=False,  # Is it necessary to call prediction for every day during backtesting?\n",
    "                             # Set it to true if you suspect that get_features is looking forward.\n",
    "    competition_type='stocks_nasdaq100',  # competition type\n",
    "    lookback_period=365,      # how many calendar days are needed by the predict function to generate the output\n",
    "    start_date='2006-01-01',  # backtest start date\n",
    "    build_plots=True          # do you need the chart?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What libraries are available?\n",
    "\n",
    "Our library makes extensive use of xarray: \n",
    "\n",
    "[xarray](http://xarray.pydata.org/en/stable/)\n",
    "\n",
    "pandas:\n",
    "\n",
    "[pandas](https://pandas.pydata.org/)\n",
    "\n",
    "and numpy:\n",
    "\n",
    "[numpy](https://numpy.org/)\n",
    "\n",
    "Function definitions can be found in the qnt folder in your private root directory.\n",
    "\n",
    "```python\n",
    "# Import basic libraries.\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import quantnet libraries.\n",
    "import qnt.data    as qndata  # load and manipulate data\n",
    "import qnt.output as output   # manage output\n",
    "import qnt.backtester as qnbt # backtester\n",
    "import qnt.stats   as qnstats # statistical functions for analysis\n",
    "import qnt.graph   as qngraph # graphical tools\n",
    "import qnt.ta      as qnta    # indicators library\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# May I import libraries?\n",
    "\n",
    "Yes, please refer to the file **init.ipynb** in your home directory. You can dor example use:\n",
    "\n",
    "! conda install -y scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load data?\n",
    "\n",
    "Futures:\n",
    "```python\n",
    "data= qndata.futures.load_data(tail = 15*365, dims = (\"time\", \"field\", \"asset\"))\n",
    "```\n",
    "\n",
    "BTC Futures:\n",
    "```python\n",
    "data= qndata.cryptofutures.load_data(tail = 15*365, dims = (\"time\", \"field\", \"asset\"))\n",
    "```\n",
    "\n",
    "Cryptocurrencies:\n",
    "```python\n",
    "data= qndata.crypto.load_data(tail = 15*365, dims = (\"time\", \"field\", \"asset\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to view a list of all tickers?\n",
    "\n",
    "```python\n",
    "data.asset.to_pandas().to_list()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to see which fields are available?\n",
    "\n",
    "```python\n",
    "data.field.to_pandas().to_list()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load specific tickers?\n",
    "\n",
    "```python\n",
    "data = qndata.futures.load_data(tail=15 * 365, assets=['F_O', 'F_DX', 'F_GC'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to select specific tickers after loading all data?\n",
    "\n",
    "```python\n",
    "def get_data_filter(data, assets):\n",
    "    filler= data.sel(asset=assets)\n",
    "    return filler\n",
    "\n",
    "get_data_filter(data, [\"F_O\", \"F_DX\", \"F_GC\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get the prices for the previous day?\n",
    "\n",
    "```python\n",
    "qnta.shift(data.sel(field=\"open\"), periods=1)\n",
    "```\n",
    "\n",
    "or:\n",
    "\n",
    "```python\n",
    "data.sel(field=\"open\").shift(time=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I get a list of the top 10 assets ranked by Sharpe ratio?\n",
    "\n",
    "```python\n",
    "import qnt.stats as qnstats\n",
    "\n",
    "data= qndata.futures.load_data(tail=16 * 365)\n",
    "\n",
    "def get_best_instruments(data, weights, top_size):\n",
    "    # compute statistics:\n",
    "    stats_per_asset= qnstats.calc_stat(data, weights, per_asset=True)\n",
    "    # calculate ranks of assets by \"sharpe_ratio\":\n",
    "    ranks= (-stats_per_asset.sel(field=\"sharpe_ratio\")).rank(\"asset\")\n",
    "    # select top assets by rank \"top_period\" days ago:\n",
    "    top_period= 300\n",
    "    rank= ranks.isel(time=-top_period)\n",
    "    top= rank.where(rank <= top_size).dropna(\"asset\").asset\n",
    "\n",
    "    # select top stats:\n",
    "    top_stats= stats_per_asset.sel(asset=top.values)\n",
    "\n",
    "    # print results:\n",
    "    print(\"SR tail of the top assets:\")\n",
    "    display(top_stats.sel(field=\"sharpe_ratio\").to_pandas().tail())\n",
    "\n",
    "    print(\"avg SR = \", top_stats[-top_period:].sel(field=\"sharpe_ratio\").mean(\"asset\")[-1].item())\n",
    "    display(top_stats)\n",
    "    return top_stats.coords[\"asset\"].values\n",
    "\n",
    "get_best_instruments(data, weights, 10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I check the results for only the top 10 assets ranked by Sharpe ratio?\n",
    "\n",
    "Select the top assets and then load their data:\n",
    "\n",
    "```python\n",
    "best_assets= get_best_instruments(data, weights, 10)\n",
    "\n",
    "data= qndata.futures.load_data(tail=15 * 365, assets=best_assets)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can prices be processed?\n",
    "\n",
    "Simply import standard libraries, for example **numpy**:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "high= np.log(data.sel(field=\"high\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can you reduce slippage impace when trading?\n",
    "\n",
    "Just apply some technique to reduce turnover:\n",
    "\n",
    "```python\n",
    "def get_lower_slippage(weights, rolling_time=6):\n",
    "    return weights.rolling({\"time\": rolling_time}).max()\n",
    "\n",
    "improved_weights = get_lower_slippage(weights, rolling_time=6)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use technical analysis indicators?\n",
    "\n",
    "For available indicators see the source code of the library: /qnt/ta\n",
    "\n",
    "## ATR\n",
    "\n",
    "```python\n",
    "def get_atr(data, days=14):\n",
    "    high = data.sel(field=\"high\") * 1.0 \n",
    "    low  = data.sel(field=\"low\") * 1.0 \n",
    "    close= data.sel(field=\"close\") * 1.0\n",
    "\n",
    "    return qnta.atr(high, low, close, days)\n",
    "\n",
    "atr= get_atr(data, days=14)\n",
    "```\n",
    "\n",
    "## EMA\n",
    "\n",
    "```python\n",
    "prices= data.sel(field=\"high\")\n",
    "prices_ema= qnta.ema(prices, 15)\n",
    "```\n",
    "\n",
    "## TRIX\n",
    "\n",
    "```python\n",
    "prices= data.sel(field=\"high\")\n",
    "prices_trix= qnta.trix(prices, 15)\n",
    "```\n",
    "\n",
    "## ADL and EMA\n",
    "\n",
    "```python\n",
    "adl= qnta.ad_line(data.sel(field=\"close\")) * 1.0 \n",
    "adl_ema= qnta.ema(adl, 18)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can you check the quality of your strategy?\n",
    "\n",
    "```python\n",
    "import qnt.output as qnout\n",
    "qnout.check(weights, data)\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "stat= qnstats.calc_stat(data, weights)\n",
    "display(stat.to_pandas().tail())\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "import qnt.graph   as qngraph\n",
    "statistics= qnstats.calc_stat(data, weights)\n",
    "display(statistics.to_pandas().tail())\n",
    "\n",
    "performance= statistics.to_pandas()[\"equity\"]\n",
    "qngraph.make_plot_filled(performance.index, performance, name=\"PnL (Equity)\", type=\"log\")\n",
    "\n",
    "display(statistics[-1:].sel(field = [\"sharpe_ratio\"]).transpose().to_pandas())\n",
    "qnstats.print_correlation(weights, data)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example using pandas\n",
    "\n",
    "One can work with pandas DataFrames at intermediate steps and at the end convert them to xarray data structures:\n",
    "\n",
    "```python\n",
    "def get_price_pct_change(prices):\n",
    "    prices_pandas= prices.to_pandas()\n",
    "    assets= data.coords[\"asset\"].values\n",
    "    for asset in assets:\n",
    "        prices_pandas[asset]= prices_pandas[asset].pct_change()\n",
    "    return prices_pandas\n",
    "\n",
    "\n",
    "prices= data.sel(field=\"close\") * 1.0\n",
    "prices_pct_change= get_price_pct_change(prices).unstack().to_xarray()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to submit a strategy to the competition?\n",
    "\n",
    "Check that weights are fine:\n",
    "\n",
    "```python\n",
    "import qnt.output as qnout\n",
    "qnout.check(weights, data)\n",
    "```\n",
    "\n",
    "If everything is ok, write the weights to file:\n",
    "\n",
    "```python\n",
    "qnout.write(weights)\n",
    "```\n",
    "\n",
    "In your **personal account**:\n",
    "\n",
    "* **choose** a strategy;\n",
    "* click on the **Submit** button;\n",
    "* select the type of competition.\n",
    "\n",
    "At the beginning you will find the strategy under the **Checking** area (**Competition** > **Checking**). If Sharpe ratio is larger than 1 and technical checks are successful, the strategy will go under the **Running** area (**Competition** > **Running**). Otherwise it will be **Filtered** (**Competition** > **Filtered**) and you should inspect error and warning messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
